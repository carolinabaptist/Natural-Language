Grammatical System

Language has a grammatical system that defines its rules and structures. Grammar includes rules 
for syntax (how to organize words into sentences) and morphology (how words are formed and modified). 
These rules are fundamental for efficient and coherent communication, both in natural languages ​​
(such as English or Portuguese) and in formal languages.

Each language has its own rules that govern how sounds, words, and sentences are organized and 
understood. Even though some rules may be similar across different languages, many are unique 
and reflect the culture and history of a people.

Communication is the primary function of language. It allows people to express thoughts, emotions 
and intentions in a structured way. This is essential not only in speech and writing, but also in
the digital context, where NLP tries to decipher and generate human language to improve human-machine
interaction.

Human language is natural, that is, it develops spontaneously in individuals through social 
interaction. Unlike artificial languages ​​(such as programming languages), natural languages ​​evolve 
organically.

Languages ​​evolve naturally as people communicate and adapt language to new realities. New terms are 
created, expressions change meaning and language adapts to new social and technological contexts.

New words are created every day. This can happen due to technological innovation, cultural changes,
or influences from other languages. In PLN, dealing with these new words (called out-of-vocabulary 
words or words outside the vocabulary) is a constant challenge.

New words are constantly being added to languages due to cultural, technological, and social 
changes.

Examples:
Selfie: This word gained popularity around 2012 and was officially added to dictionaries shortly after.
Binge-watch: This became common with the rise of platforms like Netflix.
Thou: An archaic form of "you" in singular form, used frequently in Middle English and Early 
Modern English. It's no longer in everyday use except in specific contexts (e.g., poetry, 
religious texts).

Natural languages are those that have evolved organically among humans for communication.

Portuguese: A Romance language that evolved from Latin.
English: A Germanic language with significant influences from Latin and French.
Portuguese Sign Language: A visual-gestural natural language used by the deaf community 
in Portugal. It's an example of a sign language, which, like spoken languages, evolves 
naturally within communities.
Esperanto is not a natural language, but rather a constructed language (conlang). It was 
created in the late 19th century by L. L. Zamenhof with the aim of promoting international 
communication. Although it has a relatively small community of speakers, Esperanto did not 
evolve naturally from human interaction but was designed intentionally with simplified grammar 
and vocabulary from various European languages.

NLP: Field of Artificial Intelligence and Linguistics concerned with the interactions between 
computers and human natural languages.

Challenges

Language variability:  common challenge in developing dialogue systems in Natural Language 
Processing (NLP). Multiple phrases are used to express the same request. Ex: "Switch on the light!",
"Switch the light on!", "Turn the light on!" etc. Even though all these sentences have the same 
intent (turning on the light), the phrasing 
differs significantly. A well-designed dialogue system (like a chatbot or virtual assistant) 
must be able to understand the different ways people express the same idea (despite varied 
sentence structure or vocabulary) and Respond appropriately by recognizing the intent behind 
these different expressions, which may involve handling variations in syntax, politeness, or 
regional usage.

Paraphrases: Two sentences that convey the same meaning, despite having different wording

Ambiguity: The response does not fully answer the intended request. 
"Can you turn on the light, please?" "Yes, I can!" The responder acknowledges that they can turn 
on the light but does not clarify whether they will actually do so.

Ambiguity and Vagueness: "Can you turn on the light, please?" The problem: There are multiple 
lights. This introduces vagueness because it’s unclear which light the user is referring to. 
The request lacks specific information, making it ambiguous for the listener or system to 
determine the correct action.

A single sentence can have different meanings, and the source of ambiguity can vary. Ambiguity 
in language occurs when a sentence or phrase can be interpreted in multiple ways. There are 
several types of ambiguity that can arise in natural language, making it a challenging task 
for NLP systems to resolve meaning accurately.

Lexical Ambiguity: Occurs when a word has more than one meaning.
Example: "She can't bear children." This could mean "She cannot tolerate children" or "She 
is unable to give birth to children."

Syntactic Ambiguity: Occurs when a sentence can be parsed (structured) in more than one way, 
leading to different meanings.
Example: I saw the man on the hill with a telescope.

All ambiguities “are” semantic, but some are not related with lexical and syntactic ambiguity.
Examples: John and Mary are married. John kissed his wife and Peter too.

Ellipsis: omission of words in a sentence that are implied by the context.
"Can you turn on the light, please?" "Now, the radio!" "Now turn it off!" The phrase "Now the radio!" 
omits words that are understood from the previous context. 

Co-reference resolution: task of determining which words refer to the same entity in a text.
The phrase "Now turn it off!" refers to something previously mentioned, but the word "it" is 
ambiguous on its own. Based on the context, "it" could refer to either the light or the radio, 
but we understand that the speaker is likely referring to the radio (since that was mentioned last).

Noise: In voice-based systems, noise refers to external sounds like traffic, people talking, 
or poor audio quality that makes it difficult to accurately capture spoken language.
Noise in speech (background sounds) or text (typos, slang) can cause NLP models to 
misunderstand the intended meaning or fail to correctly process the input.

Different accents: changes how sounds are produced. For example, in some British accents, 
the "r" sound may not be pronounced at the end of words ("car" might sound like "cah"), 
while in American English, the "r" is more pronounced. These differences can confuse speech 
recognition systems if they are not trained to handle multiple accents.

Age variation: Younger children often have different pronunciation patterns (e.g., mispronunciations),
a more limited vocabulary, and varying grammatical structures as they are still learning the language.
They also tend to speak at a higher pitch, with shorter and simpler sentences. Older adults may speak 
more slowly, use different vocabulary (sometimes outdated terms), and have different speech patterns 
due to factors like cognitive aging or health conditions (e.g., hearing loss or voice tremors).

Context: the same sentence can convey completely different emotions and intentions depending on 
the context. Context is critical because words and sentences don’t exist in isolation. 
Their meaning often depends on who is speaking, what was said previously and external factors 
like time, place, tone.

Sarcasm and irony: meaning that is often the opposite of the literal interpretation of words. 
Both rely heavily on context, tone, and prior knowledge to be understood correctly, which are 
things that machines typically struggle with.

Transformers are a revolutionary neural network architecture in the field of Natural Language 
Processing (NLP) and other areas of deep learning. Transformers have radically changed the way 
language models are designed and trained, surpassing previous architectures like recurrent neural 
networks (RNNs) and LSTMs (Long Short-Term Memory).

Attention Mechanism: In the context of a sentence, this means that when processing a word, 
Transformer can look at all the other words in the sequence and decide which ones to 
"pay more attention to" in order to understand the meaning of the sentence.

Self-Attention: In a sentence like "The cat sat on the mat", the self-attention mechanism 
helps the model understand that "the" refers to "cat" and "mat" is a location, without 
needing to process the words in an order strict.

Parallelization: Transformers can process all words in the sequence at the same time. 
This makes them much faster and more efficient in training and inference.

The scientific method with a focus on data collection as a key step

First, scientists identify a problem or make an observation that leads to a research question. 
This question is the basis for further investigation.

A hypothesis is formulated, which is a testable and falsifiable prediction that provides 
a tentative explanation to the research question.

Data Collection involves planning and gathering data in a structured manner. It is critical 
to collect sufficient and relevant data to test the hypothesis. The Data Collection step 
you've highlighted is critical because the quality and reliability of the data directly 
impact the outcomes of the research. This step often involves planning the methodology, 
determining how to minimize bias, and ensuring that the sample size is adequate.

Researchers design and conduct experiments that will allow them to test their hypothesis 
under controlled conditions.

After collecting data, it's analyzed to check the results and determine whether they 
support the hypothesis or not.

For any machine learning model to perform well, a large amount of data is required. 
This data serves as the foundation for both training and testing models. During 
training, the model learns patterns from the data, and during testing, the model 
is evaluated on how well it can generalize to new, unseen data.

Annotated data: data that has been labeled with relevant information that the model 
can use to learn. For example, in NLP tasks like sentiment analysis, text data might 
be labeled with tags like "positive," "negative," or "neutral." In a named entity 
recognition task, entities like people's names, locations, or dates would be annotated 
within the text.

Finally, researchers draw conclusions based on the analysis. They decide if the 
hypothesis was correct or if further experimentation is needed.

To train and test our models, we need data and sometimes annotated data.

Corpus: is a collection of texts used for Sentiment Analysis or PoS Tagging. Corpora 
is the plural. Corpora come in many forms and can either have annotations or be 
unannotated. Annotations are extra layers of information added to the text, such
as part-of-speech tags, syntactic structure, semantic roles, or even sentiment 
indicators. These annotations make it easier for machines and researchers to 
analyze specific linguistic features in the text.

Sentiment Analysis: Reviews or comments in a corpus might be annotated to 
indicate their overall sentiment. For instance, each review could be labeled 
as positive, neutral, or negative, allowing researchers or machine learning 
models to identify the emotional tone of the text.

Morpho-syntactic Tagging: In another example, individual words within a text 
can be annotated with their morpho-syntactic category. This means that each 
word is labeled according to its grammatical function, such as verb, noun, 
adjective, etc. This kind of annotation helps in tasks like part-of-speech 
tagging or syntactic parsing, which are key to understanding the structure 
of sentences.

Building Corpora involves creating and curating large collections of texts, 
and it can be a time-consuming and expensive process.

Often, experts in linguistics, data science, or specific domains are required
to annotate or label the data accurately. For instance, tagging a corpus with 
complex annotations like syntactic structures or specific domain knowledge 
(legal, medical texts) requires specialized expertise, which adds to the cost and time.

To reduce costs and speed up the process, some projects rely on crowdsourcing. 
This involves using platforms where a large number of non-experts, or the "crowd," 
can contribute to the labeling of data. A well-known platform for this is 
Amazon Mechanical Turk, where workers are paid to complete small tasks, such as 
labeling the sentiment of a review or categorizing text snippets.

Here are some examples of NLP tasks that require annotated data where the annotators 
do not need to be experts:

1. Sentiment Analysis: Annotators label text (such as reviews, tweets, or comments) 
as positive, neutral, or negative based on the overall sentiment. Basic human 
understanding of emotions and attitudes is sufficient to decide whether a text 
conveys a positive, negative, or neutral sentiment.
2. Named Entity Recognition (NER): Annotators mark specific entities in text, like 
names of people, locations, or dates. Identifying names or locations does not 
require specialized knowledge, just an understanding of the language.
3. Text Classification: Assigning a category to a piece of text, such as whether 
an article is about sports, politics, or technology.

One notable example of corpus-building involves text alignment, an NLP task. 
Text alignment is the process of aligning corresponding segments of text 
(such as sentences or paragraphs) between two or more languages or different 
versions of the same language. This can be crucial for tasks like machine 
translation and comparative linguistic studies.

CLUE-Aligner is a project led by Anabela Barreiro that focuses on text alignment. 
The tool developed in this project automates the process of aligning texts across 
languages, typically aligning parallel texts in bilingual corpora.

Another key example of corpus building relates to text segmentation, a NLP task 
that involves dividing texts into meaningful segments, such as sentences, paragraphs, 
or topics. This task is essential for many natural language processing applications 
like summarization, information retrieval, and text analysis.

In some cases, you might not have an existing corpus or dataset to work with when 
developing a natural language processing (NLP) system. In these situations, a 
common solution is to use a Wizard of Oz approach.

Wizard of Oz refers to a method where a human (the "wizard") simulates the behavior 
of the system being developed. This is done without the end-user knowing that there 
isn’t a fully functional automated system in place. The goal is to collect data on 
how users interact with the system and how it is expected to function in real-world 
scenarios.  If you don’t have an existing corpus to understand how your NLP system 
will be used, the Wizard of Oz approach allows you to simulate the system's 
functionality. A human mimics the system’s responses to gather insights into 
user interactions. And collect data: As users interact with the system, you generate 
real-world data, which can later be used to build or expand a corpus.

When building annotated corpora, it's crucial to evaluate the quality of the annotations.
One key method to assess this is by measuring the inter-annotator agreement (IAA). 
This metric shows how consistently different annotators label the same data. 
Inter-annotator agreement is a way to check the quality of the annotations by 
assessing how much annotators agree on their labeling or tagging. 
High agreement typically suggests that the task is clear, the guidelines are 
well-defined, and the annotators are doing a good job.

If the agreement among annotators is low, it indicates a potential problem such as 
bad Guidelines. The instructions for how to annotate the data may be unclear or incomplete.

Inconsistent or vague guidelines make it difficult for annotators to apply the same 
criteria across the dataset. Or The task is very difficult: Some NLP tasks, like 
labeling complex emotions or identifying abstract entities, may inherently be 
subjective or ambiguous. Even with clear guidelines, some tasks may be naturally 
prone to lower agreement due to the complexity of the language or concepts involved.

Depending on the nature of the task and the number of annotators involved, various 
statistical methods can be used to quantify agreement. 

Cohen's Kappa Coefficient: Used when there are two annotators working on the same 
dataset. It calculates how much the annotators agree beyond what would be expected by chance.

Fleiss’ Kappa: When there are more than two annotators, such as in large-scale annotation projects 
or crowdsourced tasks. Fleiss' kappa is an extension of Cohen’s kappa that measures agreement between
three or more annotators. It is used when a group of annotators labels data into categories.

Window Difference: When the task involves segmenting text into meaningful parts (e.g., identifying 
sentence or topic breaks). Window Difference (WD) is a metric specifically designed to measure 
agreement in text segmentation tasks. It assesses how well the annotators agree on segment 
boundaries (e.g., where paragraphs or topics should be split in a document). 

Each NLP task may require a specialized metric to accurately measure agreement. While kappa 
metrics are ideal for categorical labeling tasks, other metrics like Window Difference are 
designed for tasks like segmentation.

Data Splits
In machine learning, particularly for NLP tasks, datasets are typically split into different 
subsets to ensure that models are trained and evaluated properly. 
The two most important splits are:

Train set: This subset is used to train the model, meaning the model learns patterns, structures,
and relationships in the data.

Test set: This subset is used to evaluate the model after training. It assesses the model’s ability 
to generalize to new, unseen data and gives an indication of how well the model will perform 
in real-world scenarios. Importantly, the test set must remain separate from the training data 
to avoid overfitting, and it is not used during training.

For large language models (LLMs), like GPT or BERT, ensuring that the training data and test data 
are strictly separate—often called data hygiene—is crucial but challenging, especially with large,
diverse datasets. When data is sourced from the web, overlapping data between training and testing 
datasets can inadvertently occur.

How to Guarantee the Separation of Training and Test Data:
Data Deduplication: Before splitting the dataset, apply deduplication techniques to identify 
and remove any duplicate data across the training, validation, and test sets. Tools like 
MinHash or SimHash can be used to find near-duplicates in text corpora, which helps avoid 
overlaps between sets.
Cross-Validation: For some tasks, especially when data is limited, use k-fold cross-validation,
where the data is divided into k subsets, and the model is trained and tested k times with 
different training/test splits. This process ensures that every data point is used both for 
training and testing, but never at the same time.

In addition to the train and test sets, there are other important splits:

Validation Set: The validation set is used during the tuning process of a model, primarily 
to help adjust and fine-tune hyperparameters. This is also known as hyperparameter tuning. 
Like the test set, the validation set is not used to train the model itself. Instead, it is
used to evaluate the model's performance on unseen data during the training process, allowing 
adjustments to be made to improve performance. It’s important that the validation set is distinct 
from both the training and test sets, ensuring the model does not "see" the same data more than once.

tuning process: adjusting certain parameters, known as hyperparameters, to optimize the model's 
performance on a given task. This process is crucial because the right configuration of hyperparameters 
can significantly improve the model's ability to generalize to new, unseen data.

Hyperparameters: parameters that define the structure of the model or how it is trained, but they 
are not learned from the data itself. Instead, they are set manually before training begins. Example: 
Learning rate: Controls how quickly the model updates its parameters during training.

Development Set: The development set is used for preliminary assessment of the model’s performance. 
It helps developers make adjustments to the model before final evaluation. After the model is trained, 
the development set is often used to try out different configurations, refine algorithms, or adjust 
specific parts of the model's architecture. The development set can be used for broader tasks, including 
debugging, monitoring, and minor adjustments to the model before final testing.

Reference: é qualquer conjunto de dados usado como base para comparação ou orientação. A "referência" pode não ter o mesmo nível de rigor que um Gold Standard, mas ainda é considerada confiável o suficiente para ser usada em avaliações. A qualidade de uma referência pode variar. Embora seja confiável, não precisa necessariamente ser a melhor ou mais precisa disponível, mas deve ser adequada para a tarefa ou contexto. Usada como orientação ou comparação, mas pode não ser a melhor disponível. Pode ser suficiente em contextos menos críticos onde a precisão absoluta não é essencial.

Gold standard: um conjunto de dados ou uma coleção que foi meticulosamente organizada, verificada e validada com o mais alto nível de qualidade e precisão. Esse tipo de dataset é geralmente considerado o mais confiável e serve como referência ou benchmark para avaliação de modelos e algoritmos.

K-fold cross-validation: usada para avaliar o desempenho de um modelo de maneira mais confiável. Ela divide o conjunto de dados em K partes (ou folds) e executa K experimentos, cada um usando uma parte diferente como conjunto de teste e as outras K-1 partes como conjunto de treinamento.

O conjunto de dados é dividido aleatoriamente em K partes iguais, chamadas de folds. A aleatoriedade na divisão é importante para garantir que cada parte seja representativa da distribuição geral dos dados, evitando vieses que podem ocorrer se a divisão não for balanceada. Por exemplo, se K = 10, o conjunto de dados é dividido em 10 partes aproximadamente iguais.

Em cada um dos K experimentos, um dos folds é usado como conjunto de teste, e os outros K-1 folds são combinados para formar o conjunto de treinamento.

Assim, em cada rodada, você treina o modelo com uma parte diferente do conjunto de dados, garantindo que cada instância do conjunto de dados seja usada tanto para treinamento quanto para teste. Isso reduz o risco de sobreajuste ao avaliar o modelo, pois garante que ele tenha sido testado em diferentes subconjuntos dos dados.

A divisão aleatória garante que o conjunto de dados seja distribuído de forma equilibrada entre os folds, minimizando a possibilidade de que um fold contenha um subconjunto de dados não representativo da distribuição total (por exemplo, todos os dados de uma mesma classe). Isso melhora a robustez da avaliação.

No deep learning, essa técnica pode ser computacionalmente cara, pois exige o treinamento do modelo K vezes (um para cada fold). Como os modelos de deep learning geralmente são muito complexos e demorados para treinar, realizar o processo completo de K-fold pode ser inviável em alguns cenários.

Data Augmentation: refere-se ao conjunto de técnicas usadas para aumentar o tamanho e a variedade de um conjunto de dados, gerando novas amostras a partir das existentes. Isso é especialmente útil quando há escassez de dados de treinamento e pode ajudar a melhorar a generalização de modelos de aprendizado de máquina.

Substituição por Sinônimos: Consiste em substituir palavras de uma frase por seus sinônimos, mantendo o sentido original. Gera novas variações da mesma frase, aumentando a diversidade do conjunto de dados.
Exemplo: "O gato está dormindo no sofá" → "O felino está descansando no sofá".

Paráfrase: Reescrever uma sentença ou parágrafo com uma estrutura diferente, mas preservando o significado original. Introduz variações sem alterar o conteúdo semântico, ampliando a cobertura do conjunto de dados e melhorando a capacidade do modelo de lidar com diferentes maneiras de expressar o mesmo conceito.
Exemplo: "Ele terminou o relatório" → "O relatório foi finalizado por ele".

Rule-based Augmentation: Aplica regras linguísticas para transformar uma frase. Um exemplo comum é converter a voz ativa para a voz passiva ou vice-versa.Permite introduzir variações mais estruturadas, levando em consideração a gramática e sintaxe do idioma.
"Ela escreveu a carta" (voz ativa) → "A carta foi escrita por ela" (voz passiva).

Back Translation: Tradução de um texto para outro idioma e, em seguida, de volta para o idioma original. O texto resultante é uma variação da frase original. Gera variações naturais da frase ao passar por diferentes estruturas linguísticas. É uma forma eficaz de introduzir variação sem perder o significado.
Exemplo: "O cachorro está latindo" → (tradução para inglês) "The dog is barking" → (tradução de volta para o português) "O cão está latindo".

Random Swap: Realiza pequenas alterações nas sentenças, trocando aleatoriamente a posição de palavras.Cria variações na ordem das palavras, o que pode ajudar a melhorar a robustez do modelo. No entanto, essa técnica precisa ser usada com cuidado, pois a troca de palavras pode impactar a legibilidade e o significado.
"Ele comeu um sanduíche" → "Ele um sanduíche comeu".

Benefícios do Data Augmentation: Adiciona variações ao conjunto de dados, ajudando a evitar o sobreajuste (overfitting). Modelos treinados com dados aumentados tendem a ser mais robustos e capazes de generalizar melhor.

Text Expansion: Consiste em enriquecer o conteúdo original com texto adicional relevante, como cláusulas explicativas ou frases descritivas. Isso pode ajudar a fornecer mais contexto e detalhamento ao texto, aumentando a quantidade de dados úteis para o modelo. A expansão de texto pode melhorar a capacidade do modelo de compreender textos mais longos e contextos mais ricos, ensinando-o a lidar com maior complexidade linguística.
Exemplo: "Ela foi à praia" → "Ela, que estava muito cansada depois de uma semana de trabalho, foi à praia para relaxar."

Noise Injection: Introduzir erros intencionais no texto, como erros de digitação, ortografia ou gramática, para simular imperfeições do mundo real. Isso ajuda a treinar modelos que possam lidar com ruído nos dados.
Exemplo: "O cachorro está latindo" → "O cahorro estah latindo."

Entity Substitution: Substitui entidades nomeadas (como nomes de pessoas, locais, organizações, etc.) por outras entidades do mesmo tipo. Isso aumenta a variabilidade dos dados e melhora a generalização de modelos que precisam reconhecer entidades.
Exemplo: "John foi a Paris" → "Maria foi a Londres."
Em vez de um modelo ser treinado para reconhecer um nome específico (por exemplo, "John"), ele aprende a lidar com qualquer entidade (outros nomes de pessoas) dentro de um contexto semelhante.

Data cleaning (ou denoising): o processo de detecção e correção de erros e inconsistências nos conjuntos de dados, visando melhorar a qualidade e precisão dos dados usados para análise e modelagem. 

Toxic Data: conteúdos textuais que contêm formas prejudiciais, ofensivas ou inapropriadas que podem ser gerados, analisados ou processados em modelos.

Profanity (Palavrões): O uso de palavras de baixo calão, xingamentos ou linguagem ofensiva.
Threats and Insults (Ameaças e Insultos): Frases que contêm ameaças diretas ou indiretas e insultos, onde o objetivo é intimidar ou ofender outra pessoa.
Cyberbullying (Bullying Virtual): Comportamentos repetidos de intimidação, assédio ou abuso emocional direcionados a indivíduos online. Pode ocorrer em redes sociais, fóruns, ou qualquer outro espaço de interação digital.
Discurso de Ódio (Hate Speech): Linguagem que promove preconceito, discriminação ou violência contra indivíduos ou grupos com base em características como raça, gênero, religião, orientação sexual, etc.
Desinformação e Falsidade (Misinformation/Disinformation): Compartilhamento de informações falsas ou enganosas, que podem causar pânico, medo ou desorientação.
Stereotyping/ generalizations: prática de fazer declarações ou formar crenças que atribuem uma característica, comportamento ou traço a todos os membros de um grupo com base em observações ou preconceitos limitados.

Comparar strings — que podem ser palavras, frases, parágrafos ou até documentos inteiros — é uma tarefa fundamental. Essas comparações podem ser feitas de maneiras lexicais (baseadas em palavras) ou semânticas (baseadas no significado).
Técnicas comuns: Distância de Levenshtein, Bag-of-Words, TF-IDF

Comparação lexical envolve comparar as strings com base em suas palavras exatas (ou tokens), sem levar em conta o significado subjacente. Essa abordagem foca na igualdade exata das palavras e suas formas.
Técnicas comuns: Word Embeddings, Cosine Similarity, Siamese Networks

Exemplos em que comparar strings pode ser útil:

Correção Ortográfica: Identificar e corrigir erros de ortografia em palavras, geralmente comparando as palavras escritas com uma lista de palavras corretas.
Exemplo: "The brrown fox jumpped over the lazy dog." Aqui, as palavras "brrown" e "jumpped" são comparadas com a forma correta ("brown" e "jumped"), e a correção pode ser sugerida com base na similaridade das strings.

Técnicas: Distância de Levenshtein, Algoritmos de Fuzzy Matching

Data Cleaning: Identificar e mesclar registros duplicados que representam a mesma entidade, mesmo que as strings tenham pequenas variações.
"John Fitzgerald Kennedy", "Jonh F. Kennedy", "Jonh Kennedy" => "John Kennedy".

Técnicas: Distância de Jaccard, Fuzzy String Matching

Detecção de Plágio: Detectar plágio ao comparar um texto com outro, avaliando se há semelhanças substanciais, mesmo que algumas palavras tenham sido trocadas.
"The discovery of DNA structure was a revolutionary achievement in science." vs. "The revelation of the DNA structure was a revolutionary milestone in science."

Técnicas: Cosine Similarity, N-grams, Shingling

Code Similarity Detection: Comparar pedaços de código para identificar possíveis duplicações, reuso ou plágio de código em ambientes de desenvolvimento.
Técnicas: Abstract Syntax Trees (AST), Fingerprinting, Tokenization

Ao comparar strings ou outros dados, os termos distância e similaridade representam maneiras diferentes de medir a relação entre dois elementos. Compreender essa diferença é importante, pois alguns algoritmos utilizam métricas de similaridade, enquanto outros se baseiam em métricas de distância. Além disso, pode ser necessário normalizar esses valores para garantir que sejam comparáveis em diferentes contextos.

Métricas de distância: quantifica o quão diferentes ou distantes dois itens são. Valores maiores indicam que os itens são mais diferentes, enquanto valores menores indicam que são mais semelhantes. Exemplos: Distância Euclidiana, Distancia de Levenshtein, Distancia Jaro-Winkler

Propriedades: O valor da distância aumenta à medida que os itens se tornam mais diferentes. Quando dois itens são idênticos, a distância é zero. Algumas métricas de distância são limitadas (têm um valor máximo), enquanto outras são ilimitadas.

Edit-based metrics: permitem quantificar o quão diferentes duas strings são, contando o número mínimo de operações necessárias para transformar uma string na outra. Essas operações geralmente incluem inserções, deleções e substituições de caracteres.

1. Distancia de Levenshtein: mede o número mínimo de edições (inserções, deleções ou substituições) necessárias para transformar uma string em outra.

Inserção: Adicionar um caractere na string para igualá-la à outra.
Deleção: Remover um caractere da string para igualá-la à outra.
Substituição: Trocar um caractere de uma string para torná-la igual ao caractere correspondente na outra string.

Por exemplo, a distância de Levenshtein entre "gato" e "casa" é 3, pois requer três substituições para transformar uma string na outra.

2. Longest Common Subsequence: mede a diferença entre duas strings, permitindo apenas inserções e deleções, mas não substituições. Ela identifica sequência mais longa de caracteres que aparece na mesma ordem em ambas as strings, mas não precisa ser contínua. 
String A: "gato"
String B: "caro"
Os caracteres 'a' e 'o' aparecem nas mesmas posições relativas nas duas strings, ou seja, 'a' vem antes de 'o' em ambas.
A subsequência "ao" aparece na mesma ordem em "gato" e "caro".
Portanto, a subsequência comum mais longa (LCS) é "ao".

Distancia LCS=(Tamanho da string A−Tamanho do LCS)+(Tamanho da string B−Tamanho do LCS)

3. Hamming Distance: mede o número de posições em que os caracteres de duas strings de mesmo comprimento diferem. Ela só permite substituições.
String A: "gato"
String B: "gata"
Distância de Hamming: 1 (a última posição é diferente: 'o' vs. 'a').

4. Damerau-Levenshtein Distance: é uma extensão da distância de Levenshtein, permitindo as operações de inserção, deleção, substituição e também a transposição de dois caracteres adjacentes (troca de posição).
String A: "gato"
String B: "gaot"
Distância de Damerau-Levenshtein: 1 (uma transposição entre 'o' e 't').

5. Jaro Distance: foca em transposições de caracteres, calculando a similaridade entre duas strings com base no número de caracteres que são iguais, mas estão fora de ordem, permitindo apenas transposições. Quanto mais próximo o valor da métrica estiver de 1, mais semelhantes são as strings.
Jaro Similarity = 1/3 * (m/|s1| + m/|s2| + m-t/m)
m é o número de correspondências (caracteres iguais dentro da distância permitida).
t é o número de transposições.
∣s1∣ é o comprimento da primeira string.
∣s2∣ é o comprimento da segunda string.
Jaro Distance = 1 - Jaro Similarity

String A: "gato"
String B: "gaot"
A métrica reconheceria que 't' e 'o' estão fora de ordem, calculando a transposição necessária para alinhar as strings.

Métricas de similaridade: quantifica o quão semelhantes dois itens são. Valores maiores significam que os itens são mais semelhantes, e valores menores indicam que são mais diferentes. Exemplos: Similaridade do Cosseno, Similaridade de Jaccard, Produto interno para embeddings.

Propriedades: Valores mais altos indicam maior similaridade. Para coincidências perfeitas, as métricas de similaridade geralmente retornam 1. As métricas de similaridade são geralmente limitadas entre [0, 1] ou [-1, 1], dependendo do método.

Jaccard e Dice medem a similaridade entre duas strings. Ambas são métricas de similaridade baseadas em tokens que operam sobre conjuntos de elementos e não sobre "bags", ou seja, não consideram repetições de elementos.

Jaccard Similarity: mede a proporção entre a interseção e a união de dois conjuntos. Em outras palavras, ela compara a quantidade de elementos em comum entre dois conjuntos em relação ao total de elementos nos dois conjuntos.

Jaccard Similarity = |A ∩ B| / |A U B|
A é o conjunto de tokens da primeira string.
B é o conjunto de tokens da segunda string.

String 1: "casa azul"
String 2: "casa vermelha"
Conjuntos de tokens (palavras):
A={"casa","azul"}
B={"casa","vermelha"}
A ∩ B = {casa}
A U B = {casa, azul, vermelha}
JS = 1/3

Dice Similarity: é uma métrica que mede o grau de similaridade entre dois conjuntos, enfatizando a interseção entre eles. 
Dice Similarity = 2 x |A ∩ B| / |A|+|B|
A e B são os conjuntos de tokens das duas strings.
∣A∩B∣ é o número de elementos em comum (interseção).
∣A∣ e ∣B∣ são os tamanhos dos conjuntos.

A={"casa","azul"}
B={"casa","vermelha"}
Interseção: A∩B={"casa"}
Tamanho de A: 2
Tamanho de B: 2
DS = 2x1/4 = 1/2

Quando usamos métricas diferentes (especialmente métricas de distância), as escalas podem variar muito, tornando difícil compará-las diretamente. A normalização garante que os valores estejam em uma faixa consistente (geralmente entre 0 e 1 ou -1 e 1).
Técnicas de normalização: Normalização Min-Max, Normalização Z-score, Escalonamento Logarítmico
